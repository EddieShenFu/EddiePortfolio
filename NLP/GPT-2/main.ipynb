{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title　基本 import\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import textwrap\n",
    "import torchsnooper\n",
    "import pytorch_transformers\n",
    "import torch.nn.functional as F\n",
    "from tqdm import trange\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'GPT2-Chinese'...\n",
      "remote: Enumerating objects: 199, done.\u001b[K\n",
      "remote: Total 199 (delta 0), reused 0 (delta 0), pack-reused 199\u001b[K\n",
      "Receiving objects: 100% (199/199), 13.41 MiB | 1.49 MiB/s, done.\n",
      "Resolving deltas: 100% (97/97), done.\n"
     ]
    }
   ],
   "source": [
    "#@title 下載 GPT-Chinese\n",
    "\n",
    "GITHUB_REPO = \"GPT2-Chinese\"\n",
    "!rm -rf {GITHUB_REPO}\n",
    "!git clone https://github.com/Morizeyao/{GITHUB_REPO}.git {GITHUB_REPO}\n",
    "if not GITHUB_REPO in sys.path:\n",
    "    sys.path += [GITHUB_REPO]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sed: illegal option -- r\n",
      "usage: sed script [-Ealn] [-i extension] [file ...]\n",
      "       sed [-Ealn] [-i extension] [-e script] ... [-f script_file] ... [file ...]\n",
      "--2020-02-03 11:35:34--  https://docs.google.com/uc?export=download&confirm=&id=1Z8WdVYgBj01BHU4syjlY9qj3KBfEFP2D\n",
      "Resolving docs.google.com (docs.google.com)... 172.217.160.78\n",
      "Connecting to docs.google.com (docs.google.com)|172.217.160.78|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/html]\n",
      "Saving to: ‘10layers_12heads_1024len_768embd_full_corpus_16bsize.zip’\n",
      "\n",
      "10layers_12heads_10     [ <=>                ]   3.24K  --.-KB/s    in 0s      \n",
      "\n",
      "2020-02-03 11:35:35 (6.46 MB/s) - ‘10layers_12heads_1024len_768embd_full_corpus_16bsize.zip’ saved [3318]\n",
      "\n",
      "Archive:  10layers_12heads_1024len_768embd_full_corpus_16bsize.zip\n",
      "  End-of-central-directory signature not found.  Either this file is not\n",
      "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
      "  latter case the central directory and zipfile comment will be found on\n",
      "  the last disk(s) of this archive.\n",
      "unzip:  cannot find zipfile directory in one of 10layers_12heads_1024len_768embd_full_corpus_16bsize.zip or\n",
      "        10layers_12heads_1024len_768embd_full_corpus_16bsize.zip.zip, and cannot find 10layers_12heads_1024len_768embd_full_corpus_16bsize.zip.ZIP, period.\n",
      "rm: config.json: No such file or directory\n",
      "rm: pytorch_model.bin: No such file or directory\n",
      "rm: vocab_small.txt: No such file or directory\n",
      "mv: rename home/ec2-user/SageMaker/tmp/GPT2-Chinese/model/10layers_12heads_1024len_768embd_full_corpus_16bsize/config.json to config.json: No such file or directory\n",
      "mv: rename home/ec2-user/SageMaker/tmp/GPT2-Chinese/model/10layers_12heads_1024len_768embd_full_corpus_16bsize/pytorch_model.bin to pytorch_model.bin: No such file or directory\n",
      "mv: rename home/ec2-user/SageMaker/tmp/GPT2-Chinese/cache/vocab_small.txt to vocab_small.txt: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "#@title 下載、解壓縮模型\n",
    "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1Z8WdVYgBj01BHU4syjlY9qj3KBfEFP2D' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1Z8WdVYgBj01BHU4syjlY9qj3KBfEFP2D\" -O 10layers_12heads_1024len_768embd_full_corpus_16bsize.zip && rm -rf /tmp/cookies.txt\n",
    "\n",
    "pretrained_model = '10layers_12heads_1024len_768embd_full_corpus_16bsize'\n",
    "\n",
    "!unzip {pretrained_model}.zip\n",
    "sagemaker_base_path = 'home/ec2-user/SageMaker/tmp/GPT2-Chinese'\n",
    "config_file = 'config.json'\n",
    "model_ckpt = \"pytorch_model.bin\"\n",
    "vocab_file = \"vocab_small.txt\"\n",
    "\n",
    "!rm {config_file} {model_ckpt} {vocab_file}\n",
    "\n",
    "!mv {sagemaker_base_path}/model/{pretrained_model}/{config_file} {config_file}\n",
    "!mv {sagemaker_base_path}/model/{pretrained_model}/{model_ckpt} {model_ckpt}\n",
    "!mv {sagemaker_base_path}/cache/{vocab_file} {vocab_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'config.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-bceed7340a94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# make model output attentions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpytorch_transformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGPT2Config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_json_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_attentions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pytorch_transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_json_file\u001b[0;34m(cls, json_file)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfrom_json_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;34m\"\"\"Constructs a `BertConfig` from a json file of parameters.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'config.json'"
     ]
    }
   ],
   "source": [
    "#@title 載入模型以及 Tokenizer\n",
    "\n",
    "from tokenizations import tokenization_bert\n",
    "\n",
    "# make model output attentions\n",
    "config = pytorch_transformers.GPT2Config.from_json_file(config_file)\n",
    "config.output_attentions = True\n",
    "\n",
    "\n",
    "model = pytorch_transformers.GPT2LMHeadModel.from_pretrained(\".\", config=config)\n",
    "tokenizer = tokenization_bert.BertTokenizer(vocab_file=vocab_file)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "model.eval()\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
